{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com o algoritmo de classificação ID3 (Decision Tree)\n",
    "\n",
    "Como mostralo em aulas, o algoritmo de classificação ID3 necessita de uma regra geral chamada de Ganho de Informação, para indicar quais são os atributos a serem selecionados desde a raíz até um ramo que determina a folha (resposta do problema).\n",
    "\n",
    "A seguir são apresentados o carregamento dos dados simples do exemplo \"Jogar Tênis\" e a função que devolve o Ganho de Informação para um conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "2 3 5 9\n",
      "3 2 5 9\n",
      "0 4 5 9\n",
      "1 3 5 9\n",
      "2 4 5 9\n",
      "2 2 5 9\n",
      "4 3 5 9\n",
      "1 6 5 9\n",
      "3 3 5 9\n",
      "2 6 5 9\n",
      "[0.24674981977443922, 0.029222565658954758, 0.15183550136234147, 0.04812703040826938]\n",
      "0.246749819774\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def entropia(q):\n",
    "    if q in (0, 1):\n",
    "        return 0\n",
    "    return -(q * log(q, 2) + (1 - q) * log(1 - q, 2))\n",
    "\n",
    "\n",
    "def ganho_info(ds, base_attr, value=None):\n",
    "    if value:\n",
    "        ds = ds[ds[:, base_attr] == value]\n",
    "        \n",
    "    classes = set(ds[:, -1])\n",
    "    a = [len(ds[ds[:, -1] == c]) for c in classes]\n",
    "    \n",
    "    \n",
    "    h = entropia(float(a[0]) / sum(a))\n",
    "    a_obj = list()\n",
    "    for value in set(ds[:, base_attr]):\n",
    "        ds_obj = ds[ds[:, base_attr] == value]\n",
    "        a_obj.append([len(ds_obj[ds_obj[:, -1] == c]) for c in classes])\n",
    "    \n",
    "    sobra = 0\n",
    "    for d in a_obj:\n",
    "        print d[0], d[1], a[0], a[1]\n",
    "        sobra += (float(d[0] + d[1]) / (a[0] + a[1])) * entropia(float(max(d[0], d[1])) / (d[0] + d[1]))\n",
    "    \n",
    "    return h - sobra\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset = np.array([\n",
    "        ['D1', 'sol', 'quente', 'alta', 'fraco', 'não'],\n",
    "        ['D2', 'sol', 'quente', 'alta', 'forte', 'não'],\n",
    "        ['D3', 'nublado', 'quente', 'alta', 'fraco', 'sim'],\n",
    "        ['D4', 'chuva', 'suave', 'alta', 'fraco', 'sim'],\n",
    "        ['D5', 'chuva', 'frio', 'normal', 'fraco', 'sim'],\n",
    "        ['D6', 'chuva', 'frio', 'normal', 'forte', 'não'],\n",
    "        ['D7', 'nublado', 'frio', 'normal', 'forte', 'sim'],\n",
    "        ['D8', 'sol', 'suave', 'alta', 'fraco', 'não'],\n",
    "        ['D9', 'sol', 'frio', 'normal', 'fraco', 'sim'],\n",
    "        ['D10', 'chuva', 'suave', 'normal', 'fraco', 'sim'],\n",
    "        ['D11', 'sol', 'suave', 'normal', 'forte', 'sim'],\n",
    "        ['D12', 'nublado', 'suave', 'alta', 'forte', 'sim'],\n",
    "        ['D13', 'nublado', 'quente', 'normal', 'fraco', 'sim'],\n",
    "        ['D14', 'chuva', 'suave', 'alta', 'forte', 'não']\n",
    "    ])\n",
    "    \n",
    "    attrs = range(1, len(dataset[0]) - 1)\n",
    "    print attrs\n",
    "    ganhos = [ganho_info(dataset, attr) for attr in attrs]\n",
    "    print ganhos\n",
    "    print max(ganhos)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código acima, e mostrado como obter o nó raiz da ID3 utilizando o ganho de informação. Uma boa tarefa para aumentar o conhecimento na manipulação de dados em python e numpy é completar os ramos dessa ID3 utilizando como limiar uma quantidade de classes respondidas pelos testes em cada ramo.\n",
    "\n",
    "No exemplo abaixo, é mostrado como carregar uma base de dados da UCI e utilizar o classificador ID3 obtido por meio scikit learn. A base de dados é a *Car Evaluation Data Set* ([https://archive.ics.uci.edu/ml/datasets/Car+Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)).\n",
    "\n",
    "O *dataset* possui os seguintes atributos:\n",
    "* buying: vhigh, high, med, low. \n",
    "* maint: vhigh, high, med, low. \n",
    "* doors: 2, 3, 4, 5more. \n",
    "* persons: 2, 4, more. \n",
    "* lug_boot: small, med, big. \n",
    "* safety: low, med, high. \n",
    "\n",
    "E as seguintes classes: unacc, acc, good, vgood\n",
    "\n",
    "### Carregamento da base de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vhigh' 'vhigh' '2' ... 'small' 'low' 'unacc']\n",
      " ['vhigh' 'vhigh' '2' ... 'small' 'med' 'unacc']\n",
      " ['vhigh' 'vhigh' '2' ... 'small' 'high' 'unacc']\n",
      " ...\n",
      " ['low' 'low' '5more' ... 'big' 'low' 'unacc']\n",
      " ['low' 'low' '5more' ... 'big' 'med' 'good']\n",
      " ['low' 'low' '5more' ... 'big' 'high' 'vgood']]\n",
      "1728\n",
      "(1728, 7)\n"
     ]
    }
   ],
   "source": [
    "from urllib2 import urlopen\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'\n",
    "filedata = urlopen(url)\n",
    "data = filedata.read()\n",
    "dataset = np.array([s.split(',') for s in data.split('\\n')][:-1])\n",
    "print dataset\n",
    "print len(dataset)\n",
    "print dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *dataset* foi carregado diretamente da página da internet utilizando `urllib2` e então carregado corretamente em um `numpy.array`.\n",
    "\n",
    "### Agora é aplicado o processo de aprendizagem utilizando o classificador ID3 do `scikit learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 0 0 2 1]\n",
      " [3 3 0 0 2 2]\n",
      " [3 3 0 0 2 0]\n",
      " ...\n",
      " [1 1 3 2 0 1]\n",
      " [1 1 3 2 0 2]\n",
      " [1 1 3 2 0 0]]\n",
      "(1728, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# transformação dos valores de categórico para numérico\n",
    "numerical_features = list()\n",
    "features = dataset[:, :-1].T\n",
    "le = LabelEncoder()\n",
    "for v in features:\n",
    "    numerical_features.append(le.fit_transform(v))\n",
    "features = np.array(numerical_features).T\n",
    "print features\n",
    "print features.shape\n",
    "# obtendo a coluna com as respostas\n",
    "labels = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 96.34%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.3, shuffle=True)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "res = clf.predict(X_test)\n",
    "misses, hits = 0, 0\n",
    "for i in range(len(res)):\n",
    "    if res[i] == Y_test[i]:\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print (\"acurácia: %.02f%%\" % (hits / float(hits + misses) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
